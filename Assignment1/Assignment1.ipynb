{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#method to generate random samples following Normal distribution in d dimensions\n",
    "def multi_gaussian(dim, num_of_samples):\n",
    "    cov_matrix = dt.make_spd_matrix(dim) #generate random symmetric, positive definite matrix\n",
    "    mean = np.random.rand(dim)\n",
    "    x = np.random.multivariate_normal(mean, cov_matrix, (num_of_samples)) #shape of x is num_of_samples x dim\n",
    "    return x\n",
    "# multi_gaussian(5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def discriminant_function(x, mean_vec, cov_matrix, dim, prior_prob):\n",
    "        if dim > 1: # multivariate gaussian\n",
    "            cov_inverse = np.linalg.inv(cov_matrix)\n",
    "            cov_det = np.linalg.det(cov_matrix)\n",
    "            return (\n",
    "                    ((- 1/2) * (mahalanobis_dist(x, mean_vec, cov_inverse))**2) \\\n",
    "                    - ((dim / 2) * ( np.log(2 * np.pi)) )\\\n",
    "                    - ( (1/2) * np.log(cov_det) ) \\\n",
    "                    + np.log(prior_prob)\n",
    "            )\n",
    "        else: # univariate gaussian\n",
    "#             print(\"euc_dist\",euclidean_dis(x, mean_vec))\n",
    "#             print(cov_matrix)\n",
    "            return (\n",
    "                    -(1/2) * euclidean_dis(x, mean_vec)**2 /  cov_matrix \\\n",
    "                    - (1/2) * (np.log(2 * np.pi * cov_matrix))\\\n",
    "                    + np.log(prior_prob)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate Euclidean distance between 2 points x and y\n",
    "def euclidean_dis(x, mean_vector):\n",
    "    cov_inverse = np.identity(x.shape[1])\n",
    "    return mahalanobis_dist(x, mean_vector, cov_inverse) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mahalanobis_dist(x, mean_vector, cov_inverse):\n",
    "#     print(\"shape of x in mahalanobis dist\", x.shape)\n",
    "    diff = ( x - mean_vector )\n",
    "    return ( np.dot( np.dot(diff, cov_inverse), diff.T ) ) ** (1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.genfromtxt('data_dhs_chap2.csv', delimiter=',', skip_header=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "misclassification error: 35.0\n"
     ]
    }
   ],
   "source": [
    "feature_1 = data[:20,:1] # first and second class\n",
    "# print(feature_1.shape)\n",
    "dim = 1\n",
    "class1_prior_prob = 0.5\n",
    "class2_prior_prob = 0.5\n",
    "predicted_class = []\n",
    "for instance in feature_1:\n",
    "    instance = instance.reshape((1,1))\n",
    "#     print(instance.shape)\n",
    "    g1 = discriminant_function(instance, np.mean(feature_1[:10]),np.var(feature_1[:10]), dim, class1_prior_prob)\n",
    "    g2 = discriminant_function(instance, np.mean(feature_1[10:20]),np.var(feature_1[10:20]), dim, class2_prior_prob)\n",
    "    if g1 > g2 :\n",
    "        predicted_class.append(0) # class 1\n",
    "    else :\n",
    "        predicted_class.append(1) # class 2\n",
    "# print(predicted_class)\n",
    "\n",
    "#find misclassification error\n",
    "target_class = data[:20, 3:].astype(int)\n",
    "\n",
    "total_instances = len(predicted_class)\n",
    "target = []\n",
    "for i in target_class:\n",
    "    target.append(i.item())\n",
    "# print(target)\n",
    "error = 0 \n",
    "for instance in range(total_instances) :\n",
    "    error += np.abs( target[instance] - predicted_class[instance] )\n",
    "avg_error_percent = (100 / total_instances) * error\n",
    "print(\"misclassification error:\", avg_error_percent)\n",
    "# avg_error = (100/n) * ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "misclassification error: 45.0\n"
     ]
    }
   ],
   "source": [
    "feature_1 = data[:,:2]\n",
    "predicted_class = []\n",
    "# print(np.mean(feature_1[:10],axis=0))\n",
    "for feature in feature_1[:20]:\n",
    "    g1 = discriminant_function(feature, np.mean(feature_1[:10],axis=0),np.cov(feature_1[:10].T), 2, 0.5)\n",
    "    g2 = discriminant_function(feature, np.mean(feature_1[10:20],axis=0),np.cov(feature_1[10:20].T), 2, 0.5)\n",
    "    if g1 - g2 > 0:\n",
    "        predicted_class.append(0)\n",
    "    else :\n",
    "        predicted_class.append(1)\n",
    "\n",
    "target_class = data[:20, 3:].astype(int)\n",
    "\n",
    "total_instances = len(predicted_class)\n",
    "target = []\n",
    "for i in target_class:\n",
    "    target.append(i.item())\n",
    "# print(target)\n",
    "error = 0 \n",
    "for instance in range(total_instances) :\n",
    "    error += np.abs( target[instance] - predicted_class[instance] )\n",
    "avg_error_percent = (100 / total_instances) * error\n",
    "print(\"misclassification error:\", avg_error_percent)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:opencv]",
   "language": "python",
   "name": "conda-env-opencv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
