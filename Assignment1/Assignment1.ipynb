{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#method to generate random samples following Normal distribution in d dimensions\n",
    "def multi_gaussian(dim, num_of_samples):\n",
    "    cov_matrix = dt.make_spd_matrix(dim) #generate random symmetric, positive definite matrix\n",
    "    mean = np.random.rand(dim)\n",
    "    x = np.random.multivariate_normal(mean, cov_matrix, (num_of_samples)) #shape of x is num_of_samples x dim\n",
    "    return x\n",
    "# multi_gaussian(5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def discriminant_function(x, mean_vec, cov_matrix, dim, prior_prob):\n",
    "        if dim > 1: # multivariate gaussian\n",
    "            cov_inverse = np.linalg.inv(cov_matrix)\n",
    "            cov_det = np.linalg.det(cov_matrix)\n",
    "            return (\n",
    "                    ((- 1/2) * (mahalanobis_dist(x, mean_vec, cov_inverse))**2) \\\n",
    "                    - ((dim / 2) * ( np.log(2 * np.pi)) )\\\n",
    "                    - ( (1/2) * np.log(cov_det) ) \\\n",
    "                    + np.log(prior_prob)\n",
    "            )\n",
    "        else: # univariate gaussian\n",
    "#             print(\"euc_dist\",euclidean_dis(x, mean_vec))\n",
    "#             print(cov_matrix)\n",
    "            return (\n",
    "                    -(1/2) * euclidean_dis(x, mean_vec)**2 /  cov_matrix \\\n",
    "                    - (1/2) * (np.log(2 * np.pi * cov_matrix))\\\n",
    "                    + np.log(prior_prob)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate Euclidean distance between 2 points x and y\n",
    "def euclidean_dis(x, mean_vector):\n",
    "    cov_inverse = np.identity(x.shape[1])\n",
    "    return mahalanobis_dist(x, mean_vector, cov_inverse) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mahalanobis_dist(x, mean_vector, cov_inverse):\n",
    "#     print(\"shape of x in mahalanobis dist\", x.shape)\n",
    "    diff = ( x - mean_vector )\n",
    "    return ( np.dot( np.dot(diff, cov_inverse), diff.T ) ) ** (1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.genfromtxt('data_dhs_chap2.csv', delimiter=',', skip_header=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dichotomizer(X, Y, dim):\n",
    "    if dim == 1 : # only 1 independent feature\n",
    "        class1_mean_vec = np.mean( X[:5] )\n",
    "        class2_mean_vec = np.mean( X[5:10] )\n",
    "        class1_cov = np.cov( X[:5] )\n",
    "        class2_cov = np.cov( X[5:10] )\n",
    "        shape = (1,1)\n",
    "    else: # more than 1\n",
    "        class1_mean_vec = np.mean( X[:5], axis=0 )\n",
    "        class2_mean_vec = np.mean( X[5:10], axis=0 )\n",
    "        class1_cov = np.cov( X[:5].T )\n",
    "        class2_cov = np.cov( X[5:10].T )\n",
    "        shape = (dim,)\n",
    "    class1_prior_prob = 0.5\n",
    "    class2_prior_prob = 0.5\n",
    "    predicted_class = []\n",
    "    for instance in X:\n",
    "        instance = instance.reshape( shape )\n",
    "        g1 = discriminant_function(instance, class1_mean_vec, class1_cov, dim, class1_prior_prob)\n",
    "        g2 = discriminant_function(instance, class2_mean_vec, class2_cov, dim, class2_prior_prob)\n",
    "        if g1 > g2 :\n",
    "            predicted_class.append(0) # class 1\n",
    "        else :\n",
    "            predicted_class.append(1) # class 2\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def empirical_training_error(target_class, predicted_class):\n",
    "    total_instances = len(predicted_class)\n",
    "    error = 0 \n",
    "    for instance in range(total_instances) :\n",
    "        error += np.abs( target_class[instance] - predicted_class[instance] )\n",
    "    avg_error_percent = (100 / total_instances) * error\n",
    "    return avg_error_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "misclassification error:  50.0\n"
     ]
    }
   ],
   "source": [
    "trg_data =  data[ 5:15 , [0,3] ] \n",
    "X = trg_data[:, 0] \n",
    "Y = trg_data[:, 1].astype(int)\n",
    "target_class = []\n",
    "for i in Y:\n",
    "    target_class.append(i.item())\n",
    "predicted_class = dichotomizer(X, Y, 1)\n",
    "print(\"misclassification error: \" , empirical_training_error(target_class, predicted_class) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "misclassification error:  40.0\n"
     ]
    }
   ],
   "source": [
    "trg_data =  data[ 5:15 , [0,1,3] ] \n",
    "X = trg_data[:, :2] \n",
    "Y = trg_data[:, -1].astype(int)\n",
    "target_class = []\n",
    "for i in Y:\n",
    "    target_class.append(i.item())\n",
    "predicted_class = dichotomizer(X, Y, 2)\n",
    "print(\"misclassification error: \" , empirical_training_error(target_class, predicted_class) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "misclassification error:  0.0\n"
     ]
    }
   ],
   "source": [
    "trg_data =  data[ 5:15 , [0,1,2,3] ] \n",
    "X = trg_data[:, :3] \n",
    "Y = trg_data[:, -1].astype(int)\n",
    "target_class = []\n",
    "for i in Y:\n",
    "    target_class.append(i.item())\n",
    "predicted_class = dichotomizer(X, Y, 3)\n",
    "print(\"misclassification error: \" , empirical_training_error(target_class, predicted_class) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:opencv]",
   "language": "python",
   "name": "conda-env-opencv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
